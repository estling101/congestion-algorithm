{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09dcd8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7f42d",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee69ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard Library ---\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# --- Third-party Libraries ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ijson\n",
    "import dtale\n",
    "\n",
    "# --- Matplotlib ---\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import LinearSegmentedColormap, Normalize\n",
    "from matplotlib.patches import Rectangle, Polygon as MplPolygon\n",
    "from matplotlib.ticker import FixedLocator\n",
    "\n",
    "# --- Shapely ---\n",
    "from shapely.geometry import (\n",
    "    Polygon, MultiPolygon, GeometryCollection\n",
    ")\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "# --- IPython / Widgets ---\n",
    "from IPython.display import display\n",
    "from ipywidgets import Checkbox, HBox, VBox, HTML\n",
    "\n",
    "# --- Enable Interactive Plotting ---\n",
    "%matplotlib widget\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfafc640",
   "metadata": {},
   "source": [
    "Allowing multiple files to be run via batch_run.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cab7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Only define injected_file_path if not set externally\n",
    "# Set injected_file_path to the realpath of the file you want to run (if running notebook individually)\n",
    "# Will overwrite if using batch_run.py, so doesn't matter in that case)\n",
    "try:\n",
    "    injected_file_path\n",
    "except NameError:\n",
    "    injected_file_path = \"/real/path/to/trajectory/file/637b023440527bf2daa5932f__post1.json\"\n",
    "\n",
    "# Always assign file_path\n",
    "file_path = injected_file_path\n",
    "\n",
    "file_id = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "# Extract post folder (assumes format has '__postX' at the end)\n",
    "post_folder = file_id.split(\"__\")[-1]  # e.g. 'post1'\n",
    "output_dir = os.path.join(\"./output\", post_folder)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Plot counter starts at 0 for each notebook run\n",
    "plot_counter = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45b5961",
   "metadata": {},
   "source": [
    "Saving plots and dataframes to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4541dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(name_suffix):\n",
    "    global plot_counter\n",
    "    plot_counter += 1\n",
    "    filename = f\"{output_dir}/plot_{file_id}_{plot_counter}_{name_suffix}.png\"\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    print(f\"Saved plot to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0520f61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(df, name_suffix):\n",
    "    filename = f\"{output_dir}/df_{file_id}_{name_suffix}.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved DataFrame to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5502dc2",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea7ac649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to Edie time bin\n",
    "def time_bin(t, dt):\n",
    "    return int(t // dt)\n",
    "\n",
    "# Convert x-position to Edie space bin\n",
    "def space_bin(x, dx):\n",
    "    return int(x // dx)\n",
    "\n",
    "# Create the main parser and Edie statistics accumulator\n",
    "def compute_edie_stats_threshold(file_path, direction=-1, dx=0.02 * 5280, dt=6, light_thresh=20, heavy_thresh=10, subsample_step=10):\n",
    "    edie_grid = defaultdict(lambda: {\"distance\": 0.0, \"time\": 0.0, \"count\": 0})\n",
    "    got_date = False\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    with open(file_path, 'r') as input_file:\n",
    "        parser = ijson.items(input_file, 'item', use_float=True)\n",
    "\n",
    "        for record in parser:\n",
    "            if record[\"direction\"] != direction:\n",
    "                continue\n",
    "\n",
    "            timestamps = np.array(record[\"timestamp\"])[::subsample_step]\n",
    "            x_positions = np.array(record[\"x_position\"])[::subsample_step]\n",
    "            if len(timestamps) < 2:\n",
    "                continue\n",
    "\n",
    "            if not got_date:\n",
    "                date = datetime.fromtimestamp(timestamps[0]).date()\n",
    "                got_date = True\n",
    "\n",
    "            for i in range(1, len(timestamps)):\n",
    "                t0, t1 = timestamps[i - 1], timestamps[i]\n",
    "                x0, x1 = x_positions[i - 1], x_positions[i]\n",
    "\n",
    "                dt_seg = t1 - t0\n",
    "                dx_seg = (x1 - x0) * direction\n",
    "                if dt_seg <= 0 or dx_seg <= 0:\n",
    "                    continue\n",
    "\n",
    "                t_bins = list(range(time_bin(t0, dt), time_bin(t1, dt) + 1))\n",
    "                x_bins = list(range(space_bin(x0, dx), space_bin(x1, dx) + 1))\n",
    "\n",
    "                for tb in t_bins:\n",
    "                    for xb in x_bins:\n",
    "                        edie_grid[(xb, tb)][\"distance\"] += dx_seg\n",
    "                        edie_grid[(xb, tb)][\"time\"] += dt_seg\n",
    "                        edie_grid[(xb, tb)][\"count\"] += 1\n",
    "\n",
    "            count += 1\n",
    "            if count % 100000 == 0:\n",
    "                print(f\"Processed {count} trajectories...\")\n",
    "    end_time = time.time()\n",
    "    print(f\"✅ Finished parsing {count} trajectories in {end_time-start_time} seconds.\")\n",
    "    \n",
    "    # Apply dual threshold filtering\n",
    "    edie_grid_light = {}\n",
    "    edie_grid_heavy = {}\n",
    "\n",
    "    for key, cell in edie_grid.items():\n",
    "        if cell[\"time\"] == 0:\n",
    "            continue\n",
    "        speed_mph = (cell[\"distance\"] / cell[\"time\"]) * 3600 / 5280\n",
    "        if speed_mph <= light_thresh:\n",
    "            edie_grid_light[key] = cell\n",
    "        if speed_mph <= heavy_thresh:\n",
    "            edie_grid_heavy[key] = cell\n",
    "\n",
    "    print(f\"🌕 Edie cells ≤ {light_thresh} mph: {len(edie_grid_light)}\")\n",
    "    print(f\"🔴 Edie cells ≤ {heavy_thresh} mph: {len(edie_grid_heavy)}\")\n",
    "\n",
    "    return edie_grid_light, edie_grid_heavy, date\n",
    "\n",
    "\n",
    "\n",
    "def union_parallelograms(parallelograms):\n",
    "    print(\"🔁 Unioning parallelograms...\")\n",
    "    t0 = time.time()\n",
    "    merged = unary_union(parallelograms)\n",
    "    t1 = time.time()\n",
    "    print(f\"✅ Union complete in {t1 - t0:.2f} seconds.\")\n",
    "    return merged\n",
    "\n",
    "def create_tilted_parallelogram(x, t, speed, length=200, time_span=60):\n",
    "    \"\"\"\n",
    "    Create a parallelogram centered at (x, t), tilted according to speed.\n",
    "    - x in feet, t in seconds\n",
    "    - speed in mph\n",
    "    \"\"\"\n",
    "    mph_to_ftps = 1.46667\n",
    "    slope = speed * mph_to_ftps  # ft/s\n",
    "    \n",
    "    half_len = length / 2\n",
    "    half_time = time_span / 2\n",
    "    \n",
    "    # Compute corners with tilt\n",
    "    corners = [\n",
    "        (t - half_time, x - slope * half_time - half_len),\n",
    "        (t - half_time, x - slope * half_time + half_len),\n",
    "        (t + half_time, x + slope * half_time + half_len),\n",
    "        (t + half_time, x + slope * half_time - half_len),\n",
    "    ]\n",
    "    return Polygon(corners)\n",
    "\n",
    "\n",
    "def split_by_thin_connections(polygons, buffer_distance=100):\n",
    "    \"\"\"\n",
    "    For each polygon in the input list, apply erosion followed by dilation.\n",
    "    This removes thin connections, possibly splitting a polygon into multiple parts.\n",
    "    \n",
    "    Args:\n",
    "        polygons (List[Polygon]): List of input polygons\n",
    "        buffer_distance (float): Buffer distance for erosion and dilation\n",
    "    \n",
    "    Returns:\n",
    "        List[Polygon]: All resulting polygons after split\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i, poly in enumerate(polygons):\n",
    "        if poly.is_empty or not isinstance(poly, Polygon):\n",
    "            continue\n",
    "\n",
    "        # Erode (shrink) to remove narrow connections\n",
    "        eroded = poly.buffer(-buffer_distance)\n",
    "        if eroded.is_empty:\n",
    "            continue\n",
    "\n",
    "        # Dilate (expand back to original size)\n",
    "        dilated = eroded.buffer(buffer_distance)\n",
    "\n",
    "        # Collect individual polygons\n",
    "        if isinstance(dilated, (MultiPolygon, GeometryCollection)):\n",
    "            parts = [g for g in dilated.geoms if isinstance(g, Polygon) and not g.is_empty]\n",
    "            results.extend(parts)\n",
    "        elif isinstance(dilated, Polygon):\n",
    "            results.append(dilated)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_all_parallelograms(points, speeds, length=200, time_span=60):\n",
    "    parallelograms = []\n",
    "    n_points = len(points)\n",
    "    print(f\"Building parallelograms for {n_points} points...\")\n",
    "    for i, ((x, t), speed) in enumerate(zip(points, speeds)):\n",
    "        if i % 100000 == 0 and i > 0:\n",
    "            print(f\"  Processed {i} points...\")\n",
    "        poly = create_tilted_parallelogram(x, t, speed, length, time_span)\n",
    "        parallelograms.append(poly)\n",
    "    print(f\"Done creating {len(parallelograms)} parallelograms.\")\n",
    "    return parallelograms\n",
    "\n",
    "def filter_polygons_by_area(polygons, min_area=10000):\n",
    "    \"\"\"\n",
    "    Filter polygons, keeping only those with area >= min_area.\n",
    "    \"\"\"\n",
    "    if hasattr(polygons, \"geoms\"):\n",
    "        poly_list = list(polygons.geoms)\n",
    "    else:\n",
    "        poly_list = [polygons]\n",
    "\n",
    "    kept_polygons = [poly for poly in poly_list if poly.area >= min_area]\n",
    "\n",
    "    print(f\"Filtered {len(poly_list)} polygons down to {len(kept_polygons)} by area >= {min_area}\")\n",
    "    return kept_polygons\n",
    "\n",
    "\n",
    "def find_and_build_congestion_zones(\n",
    "    file_path,\n",
    "    traj_threshold_seconds=10,\n",
    "    direction=-1,\n",
    "    light_thresh=20,\n",
    "    heavy_thresh=10,\n",
    "    light_params=None,\n",
    "    heavy_params=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Combines segment extraction + polygon creation into a single pass.\n",
    "    Also returns bounds for plotting without needing full trajectories.\n",
    "    \"\"\"\n",
    "    if light_params is None:\n",
    "        light_params = {}\n",
    "    if heavy_params is None:\n",
    "        heavy_params = {}\n",
    "\n",
    "    date = None\n",
    "    got_date = False\n",
    "    count = 0\n",
    "\n",
    "    # Accumulators for raw points/speeds\n",
    "    light_points, light_speeds = [], []\n",
    "    heavy_points, heavy_speeds = [], []\n",
    "\n",
    "    # Bounds tracking\n",
    "    min_ts, max_ts = float('inf'), float('-inf')\n",
    "    min_pos, max_pos = float('inf'), float('-inf')\n",
    "    min_speed, max_speed = float('inf'), float('-inf')\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    with open(file_path, 'r') as input_file:\n",
    "        parser = ijson.items(input_file, 'item', use_float=True)\n",
    "\n",
    "        for record in parser:\n",
    "            if record[\"direction\"] != direction:\n",
    "                continue\n",
    "\n",
    "            duration = record[\"last_timestamp\"] - record[\"first_timestamp\"]\n",
    "            if duration < traj_threshold_seconds:\n",
    "                continue\n",
    "\n",
    "            if not got_date:\n",
    "                date = datetime.fromtimestamp(record[\"first_timestamp\"]).date()\n",
    "                got_date = True\n",
    "\n",
    "            x_pos = np.array(record[\"x_position\"])\n",
    "            timestamp = np.array(record[\"timestamp\"])\n",
    "\n",
    "            # Update bounds, used for plotting\n",
    "            min_ts = min(min_ts, np.min(timestamp))\n",
    "            max_ts = max(max_ts, np.max(timestamp))\n",
    "            min_pos = min(min_pos, np.min(x_pos))\n",
    "            max_pos = max(max_pos, np.max(x_pos))\n",
    "\n",
    "            # Calculate speeds (mph) for all points in trajectory. \n",
    "            speed = np.diff(x_pos) / np.diff(timestamp) * direction\n",
    "            speed = np.append(speed[0], speed)\n",
    "            speed *= 0.681818  # ft/s → mph\n",
    "\n",
    "            min_speed = min(min_speed, np.min(speed))\n",
    "            max_speed = max(max_speed, np.max(speed))\n",
    "\n",
    "            def find_segments(threshold, points_accum, speeds_accum):\n",
    "                mask = (speed > 0) & (speed <= threshold) # mask of speed-array. E.g [True,True,False,True,True] [8,7,25,12,13], if thresh = 20. \n",
    "                in_segment = False\n",
    "                segment_start = 0\n",
    "\n",
    "                for i in range(len(mask)):\n",
    "                    # If we hit a True in the mask and we’re not already inside a segment, this marks the beginning of a congestion segment.\n",
    "                    if mask[i] and not in_segment:\n",
    "                        segment_start = i\n",
    "                        in_segment = True\n",
    "\n",
    "                    #If the mask switches back to False and we were inside a segment, then we just found the end of that congestion segment.\n",
    "                    elif not mask[i] and in_segment:\n",
    "                        segment_end = i - 1\n",
    "                        in_segment = False\n",
    "\n",
    "                        # Saves the start and end point of the segment: Each point is (position, timestamp) Stored in points_accum. \n",
    "                        # Also stores the speeds at those two endpoints into speeds_accum.\n",
    "                        points_accum.extend(zip(\n",
    "                            [x_pos[segment_start], x_pos[segment_end]],\n",
    "                            [timestamp[segment_start], timestamp[segment_end]]\n",
    "                        ))\n",
    "                        speeds_accum.extend([speed[segment_start], speed[segment_end]])\n",
    "\n",
    "                # If we reach the end of the trajectory while still inside a segment, then the segment extends to the last data point.\n",
    "                if in_segment:\n",
    "                    segment_end = len(mask) - 1\n",
    "                    points_accum.extend(zip(\n",
    "                        [x_pos[segment_start], x_pos[segment_end]],\n",
    "                        [timestamp[segment_start], timestamp[segment_end]]\n",
    "                    ))\n",
    "                    speeds_accum.extend([speed[segment_start], speed[segment_end]])\n",
    "\n",
    "            # finds low-speed stretches (light or heavy congestion) and saves their start/end points for later polygon building.\n",
    "            find_segments(light_thresh, light_points, light_speeds)\n",
    "            find_segments(heavy_thresh, heavy_points, heavy_speeds)\n",
    "\n",
    "            count += 1\n",
    "            if count % 100000 == 0:\n",
    "                print(f\"Processed {count} trajectories...\")\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(f\"✅ Finished parsing {count} trajectories in {t1 - t0:.2f}s\")\n",
    "    print(f\"{file_path}, {date} → Collected (light={len(light_points)}, heavy={len(heavy_points)}) points.\")\n",
    "\n",
    "    # Build polygons\n",
    "    print(\"\\n🔹 Building light congestion zones...\")\n",
    "    light_polygons = create_congestion_zones_from_points(light_points, light_speeds, **light_params)\n",
    "\n",
    "    print(\"\\n🔹 Building heavy congestion zones...\")\n",
    "    heavy_polygons = create_congestion_zones_from_points(heavy_points, heavy_speeds, **heavy_params)\n",
    "\n",
    "    # bounds for plotting\n",
    "    bounds = {\n",
    "        \"timestamps\": (min_ts, max_ts),\n",
    "        \"positions\": (min_pos, max_pos),\n",
    "        \"speeds\": (max(0, min_speed), max_speed)\n",
    "    }\n",
    "\n",
    "    return light_polygons, heavy_polygons, date, bounds\n",
    "\n",
    "\n",
    "def create_congestion_zones_from_points(\n",
    "    points,\n",
    "    speeds,\n",
    "    length=250,\n",
    "    time_span=30,\n",
    "    min_area=500000,\n",
    "    simplify_tolerance=0,\n",
    "    label=None,\n",
    "    union=True,\n",
    "    detailed_zone=True,\n",
    "    min_area_hulls=500000,\n",
    "    buffer_distance=None,\n",
    "    fill_gaps_distance=None\n",
    "):\n",
    "    \n",
    "    t0 = time.time()\n",
    "    print(f\"\\n🔹 Building congestion polygon for: {label or 'Unnamed'}\")\n",
    "    print(f\"✅ Received {len(points)} points.\")\n",
    "\n",
    "    # Step 1: Build parallelograms\n",
    "    parallelograms = build_all_parallelograms(points, speeds, length=length, time_span=time_span)\n",
    "    if not union:\n",
    "        return parallelograms\n",
    "\n",
    "    # Step 2: Union, filter, simplify\n",
    "    congestion_polygon = union_parallelograms(parallelograms)\n",
    "    filtered_by_area = filter_polygons_by_area(congestion_polygon, min_area=min_area)\n",
    "\n",
    "    if buffer_distance is not None:\n",
    "        filtered_by_area = split_by_thin_connections(filtered_by_area, buffer_distance=buffer_distance)\n",
    "\n",
    "    if fill_gaps_distance is not None:\n",
    "        filtered_by_area = fill_polygon_gaps(filtered_by_area, buffer_distance=fill_gaps_distance)\n",
    "\n",
    "    if detailed_zone:\n",
    "        simplified = simplify_polygons(filtered_by_area, tolerance=simplify_tolerance)\n",
    "        print(f\"✅ Detailed Zone processed in {time.time() - t0:.2f}s\")\n",
    "        return simplified\n",
    "\n",
    "    convexified = [poly.convex_hull for poly in filtered_by_area]\n",
    "    merged_convex = unary_union(convexified)\n",
    "    merged_list = [g for g in getattr(merged_convex, \"geoms\", [merged_convex]) if isinstance(g, Polygon)]\n",
    "    final_polygons = [poly for poly in merged_list if poly.area >= min_area_hulls]\n",
    "    print(f\"✅ Polygon processed in {time.time() - t0:.2f}s\")\n",
    "    return final_polygons\n",
    "\n",
    "\n",
    "def simplify_polygons(polygons, tolerance=1000):\n",
    "    # If MultiPolygon, simplify each geometry\n",
    "    if hasattr(polygons, \"geoms\"):\n",
    "        simplified_geoms = [poly.simplify(tolerance, preserve_topology=True) for poly in polygons.geoms]\n",
    "        return MultiPolygon(simplified_geoms)\n",
    "    elif isinstance(polygons, Polygon):\n",
    "        return polygons.simplify(tolerance, preserve_topology=True)\n",
    "    else:\n",
    "        # If it's a list of polygons\n",
    "        simplified = [poly.simplify(tolerance, preserve_topology=True) for poly in polygons]\n",
    "        return simplified\n",
    "\n",
    "def fill_polygon_gaps(polygons, buffer_distance=100):\n",
    "    \"\"\"\n",
    "    Slightly dilate (expand) each polygon and merge with the original to fill small gaps.\n",
    "    \n",
    "    Args:\n",
    "        polygons (List[Polygon]): Input polygons\n",
    "        buffer_distance (float): Distance to buffer for filling\n",
    "    \n",
    "    Returns:\n",
    "        List[Polygon]: Cleaned, gap-filled polygons\n",
    "    \"\"\"\n",
    "    filled_polygons = []\n",
    "    \n",
    "    for poly in polygons:\n",
    "        if poly.is_empty or not isinstance(poly, Polygon):\n",
    "            continue\n",
    "        \n",
    "        # Expand slightly\n",
    "        dilated = poly.buffer(buffer_distance)\n",
    "        \n",
    "        # Merge with original to preserve finer detail\n",
    "        merged = poly.union(dilated)\n",
    "\n",
    "        # Simplify topology (optional)\n",
    "        if isinstance(merged, (MultiPolygon, GeometryCollection)):\n",
    "            parts = [g for g in merged.geoms if isinstance(g, Polygon)]\n",
    "            filled_polygons.extend(parts)\n",
    "        else:\n",
    "            filled_polygons.append(merged)\n",
    "    \n",
    "    return filled_polygons\n",
    "    \n",
    "def edie_cell_to_polygon(x_bin, t_bin, dx=160, dt=30):\n",
    "    x0 = x_bin * dx / 5280\n",
    "    x1 = (x_bin + 1) * dx / 5280\n",
    "    t_start = t_bin * dt\n",
    "    t_end = (t_bin + 1) * dt\n",
    "    \n",
    "    # The corners of the rectangle in (time, mile_marker) coordinates\n",
    "    corners = [\n",
    "        (t_start, x0),\n",
    "        (t_start, x1),\n",
    "        (t_end, x1),\n",
    "        (t_end, x0),\n",
    "        (t_start, x0),  # Close polygon by repeating the first point\n",
    "    ]\n",
    "    \n",
    "    return Polygon(corners)\n",
    "\n",
    "\n",
    "def interactive_plot_edies_polys_from_bounds(bounds, patches_by_label):\n",
    "    plt.rc('font', family='serif', size=14)\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "    # Set axis limits from bounds\n",
    "    min_ts, max_ts = bounds[\"timestamps\"]\n",
    "    min_pos, max_pos = bounds[\"positions\"]\n",
    "    min_speed, max_speed = bounds[\"speeds\"]\n",
    "\n",
    "    ax.set_xlim(min_ts, max_ts)\n",
    "    ax.set_ylim(min_pos / 5280, max_pos / 5280)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Mile Marker\")\n",
    "\n",
    "    # Colorbar\n",
    "    colors = [plt.cm.jet(x) for x in np.linspace(1, 0.5, 256)]\n",
    "    green_to_red = LinearSegmentedColormap.from_list('GreenToRed', colors, N=256)\n",
    "    norm = Normalize(vmin=0, vmax=min(max_speed, 55))\n",
    "    sm = ScalarMappable(cmap=green_to_red, norm=norm)\n",
    "    sm.set_array([])\n",
    "    plt.colorbar(sm, ax=ax, label='Speed (mph)', pad=0.01)\n",
    "\n",
    "    # Format time axis\n",
    "    ticks_loc = ax.get_xticks().tolist()\n",
    "    ax.set_xticks(ticks_loc)\n",
    "    labels = [datetime.fromtimestamp(ts, tz=timezone(timedelta(hours=-6))).strftime('%H:%M:%S') for ts in ticks_loc]\n",
    "    ax.set_xticklabels(labels, rotation=45)\n",
    "\n",
    "    # Hover display\n",
    "    def format_hover_info(x, y):\n",
    "        try:\n",
    "            dt = datetime.fromtimestamp(x, tz=timezone(timedelta(hours=-6)))\n",
    "            return f\"Time: {dt.strftime('%H:%M')}, Mile: {y:.2f}\"\n",
    "        except:\n",
    "            return f\"Time: {x:.2f}, Mile: {y:.2f}\"\n",
    "    ax.format_coord = format_hover_info\n",
    "\n",
    "    # --- TOGGLES ---\n",
    "    patches_controls = {}\n",
    "    toggles = []\n",
    "\n",
    "    for label, patches in patches_by_label.items():\n",
    "        for patch in patches:\n",
    "            ax.add_patch(patch)\n",
    "\n",
    "        checkbox = Checkbox(value=True, indent=False, layout={'width': '15px'})\n",
    "        color = patch.get_facecolor() if patches else \"black\"\n",
    "        label_html = HTML(f\"<span style='color:{mcolors.to_hex(color)}; font-weight:bold;'>{label.replace('_', ' ').title()}</span>\")\n",
    "        toggles.append(HBox([checkbox, label_html], layout={'align_items': 'center', 'gap': '4px'}))\n",
    "        patches_controls[label] = (patches, checkbox)\n",
    "\n",
    "    def update_display(change=None):\n",
    "        for _, (patches, checkbox) in patches_controls.items():\n",
    "            for patch in patches:\n",
    "                patch.set_visible(checkbox.value)\n",
    "        fig.canvas.draw_idle()\n",
    "\n",
    "    for _, (_, checkbox) in patches_controls.items():\n",
    "        checkbox.observe(update_display, names='value')\n",
    "\n",
    "    update_display()\n",
    "    display(VBox(toggles))\n",
    "    plt.tight_layout()\n",
    "    save_plot(\"cong_and_edie_poly\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def build_edie_patches(edie_grid, dx, dt):\n",
    "    \"\"\"Convert edie_grid to colored matplotlib Rectangles.\"\"\"\n",
    "\n",
    "    # Colormap for Edies\n",
    "    jet = plt.cm.jet\n",
    "    colors = [jet(x) for x in np.linspace(1, 0.5, 256)]\n",
    "    cmap = LinearSegmentedColormap.from_list('GreenToRed', colors, N=256)\n",
    "    norm = Normalize(vmin=0, vmax=55)\n",
    "\n",
    "    patches = []\n",
    "    for (x_bin, t_bin), cell in edie_grid.items():\n",
    "        if cell[\"time\"] == 0:\n",
    "            continue\n",
    "        speed_mph = (cell[\"distance\"] / cell[\"time\"]) * 3600 / 5280\n",
    "        speed_for_color = min(speed_mph, 55)\n",
    "        color = cmap(norm(speed_for_color))\n",
    "\n",
    "        x0 = x_bin * dx / 5280\n",
    "        x1 = (x_bin + 1) * dx / 5280\n",
    "        t_start = t_bin * dt\n",
    "        t_end = (t_bin + 1) * dt\n",
    "\n",
    "        rect = Rectangle((t_start, x0), t_end - t_start, x1 - x0,\n",
    "                         facecolor=color, edgecolor='none', alpha=1)\n",
    "        patches.append(rect)\n",
    "    return patches\n",
    "\n",
    "\n",
    "def convert_polys_to_miles(polygons):\n",
    "    \"\"\"\n",
    "    Converts the y-coordinates of all polygons in the list from feet to miles.\n",
    "\n",
    "    Parameters:\n",
    "        polygons (list[Polygon]): List of shapely Polygons in feet.\n",
    "\n",
    "    Returns:\n",
    "        list[Polygon]: New list with y-coordinates converted to miles.\n",
    "    \"\"\"\n",
    "    converted = []\n",
    "    for poly in polygons:\n",
    "        # poly.exterior.coords gives a list of (x, y) vertices for the outer boundary\n",
    "        # Only the y-coordinate is divided by 5280 to convert feet → miles\n",
    "        coords = [(x, y / 5280) for x, y in poly.exterior.coords]\n",
    "        converted.append(Polygon(coords))\n",
    "    return converted\n",
    "\n",
    "def build_polygon_patches(polygons, facecolor):\n",
    "    \"\"\"Create matplotlib polygon patches from shapely polygons.\"\"\"\n",
    "    patches = []\n",
    "    for poly in polygons:\n",
    "        coords = np.array(poly.exterior.coords)\n",
    "        patch = MplPolygon(coords, facecolor=facecolor, edgecolor='black', linewidth=0.8)\n",
    "        patches.append(patch)\n",
    "    return patches\n",
    "\n",
    "def compare_polygon_sets(edie_light, edie_heavy, light_polys_miles, heavy_polys_miles, dx, dt):\n",
    "    \"\"\"Convert Edie cells to polygons, combine with other polygon sets, and compute pairwise area coverage.\"\"\"\n",
    "    \n",
    "    def edie_cells_to_polygons(edie_dict, dx, dt):\n",
    "        \"\"\"Convert Edie cell dictionary to a list of shapely polygons.\"\"\"\n",
    "        print(f\"Converting {len(edie_dict)} Edie cells to polygons...\")\n",
    "        polys = []\n",
    "        for (x_bin, t_bin), cell in edie_dict.items():\n",
    "            if cell[\"time\"] == 0:\n",
    "                continue\n",
    "            polys.append(edie_cell_to_polygon(x_bin, t_bin, dx, dt))\n",
    "        print(f\"Converted to {len(polys)} polygons (excluding zero-time cells).\")\n",
    "        return polys\n",
    "    \n",
    "    def total_area(polygons):\n",
    "        \"\"\"Calculate total area of a list of polygons.\"\"\"\n",
    "        return sum(p.area for p in polygons)\n",
    "    \n",
    "    # --- Step 1: Convert Edie cells ---\n",
    "    print(\"Starting conversion of Edie light polygons...\")\n",
    "    edie_light_polygons = edie_cells_to_polygons(edie_light, dx, dt)\n",
    "    \n",
    "    print(\"Starting conversion of Edie heavy polygons...\")\n",
    "    edie_heavy_polygons = edie_cells_to_polygons(edie_heavy, dx, dt)\n",
    "    \n",
    "    # --- Step 2: Store all sets in a dict ---\n",
    "    poly_sets = {\n",
    "        \"Light Edie\": edie_light_polygons,\n",
    "        \"Heavy Edie\": edie_heavy_polygons,\n",
    "        \"Light Poly\": light_polys_miles,\n",
    "        \"Heavy Poly\": heavy_polys_miles,\n",
    "    }\n",
    "    \n",
    "    # --- Step 3: Pairwise area comparisons ---\n",
    "    print(\"\\nStarting pairwise area comparisons...\\n\")\n",
    "    results = []\n",
    "    for gt_name, gt_polys in poly_sets.items():\n",
    "        gt_area = total_area(gt_polys)\n",
    "        for pred_name, pred_polys in poly_sets.items():\n",
    "            if gt_name == pred_name:\n",
    "                continue\n",
    "            pred_area = total_area(pred_polys)\n",
    "            coverage_pct = (pred_area / gt_area * 100) if gt_area > 0 else 0\n",
    "            results.append({\n",
    "                \"Truth\": gt_name,\n",
    "                \"Approx.\": pred_name,\n",
    "                \"Coverage %\": coverage_pct\n",
    "            })\n",
    "    \n",
    "    # --- Step 4: Sort & save ---\n",
    "    print(\"\\nPairwise area coverage results:\")\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results_sorted = df_results.iloc[(df_results[\"Coverage %\"] - 100).abs().argsort()]\n",
    "    df_results_sorted = df_results_sorted[[\"Approx.\", \"Truth\", \"Coverage %\"]].round(2)\n",
    "    \n",
    "    save_df(df_results_sorted, \"coverage\")\n",
    "    print(df_results_sorted)\n",
    "    \n",
    "    return df_results_sorted\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d22dca",
   "metadata": {},
   "source": [
    "Edies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c4d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "DX_FEET = 0.02 * 5280 # 0.02 miles converted to feet\n",
    "DT_SECONDS = 6 # 6 seconds \n",
    "\n",
    "edie_light, edie_heavy, date = compute_edie_stats_threshold(\n",
    "    file_path=file_path,  # file_path from \n",
    "    dx=DX_FEET,        # 0.02 miles\n",
    "    dt=DT_SECONDS,         # 6 seconds time resolution\n",
    "    direction=-1,   # set the correct traffic direction\n",
    "    light_thresh=20,\n",
    "    heavy_thresh=10,\n",
    "    subsample_step=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e429c6a",
   "metadata": {},
   "source": [
    "Our Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7604df55",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [file_path]  # Can be changed to [file1, file2] etc if you want to run multiple files via the notebook. \n",
    "                          # Remember the last file will be used for later cells in that case.\n",
    "all_rows = []\n",
    "\n",
    "for path in file_paths:\n",
    "    polygons_light, polygons_heavy, date, bound = find_and_build_congestion_zones(\n",
    "        path,\n",
    "        light_thresh=20,\n",
    "        heavy_thresh=10,\n",
    "        \n",
    "        # polygon settings\n",
    "\n",
    "        light_params=dict(length=250,\n",
    "                            time_span=30,\n",
    "                            min_area=500000,\n",
    "                            union=True,\n",
    "                            detailed_zone=False,\n",
    "                            min_area_hulls=50000,\n",
    "                            label=\"light_sub_20\"),\n",
    "        heavy_params=dict(length=500,\n",
    "                            time_span=5,\n",
    "                            min_area=50000,\n",
    "                            union=True,\n",
    "                            detailed_zone=True,\n",
    "                            buffer_distance=5,\n",
    "                            fill_gaps_distance=5,\n",
    "                            label=\"heavy_sub_10\")\n",
    "    )\n",
    "\n",
    "    # polygons_light and polygons_heavy are already computed\n",
    "    print(f\"{path} → light zones: {len(polygons_light)}, heavy zones: {len(polygons_heavy)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc6ace8",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544de98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert polygons to miles\n",
    "light_polys_miles = convert_polys_to_miles(polygons_light)\n",
    "heavy_polys_miles = convert_polys_to_miles(polygons_heavy)\n",
    "\n",
    "# Build polygon patches\n",
    "light_poly_patches = build_polygon_patches(light_polys_miles, \"#04ff00\")\n",
    "heavy_poly_patches = build_polygon_patches(heavy_polys_miles, \"#ff0000\")\n",
    "\n",
    "# Build Edie patches\n",
    "light_edie_patches = build_edie_patches(edie_light, dx=DX_FEET, dt=DT_SECONDS)\n",
    "heavy_edie_patches = build_edie_patches(edie_heavy, dx=DX_FEET, dt=DT_SECONDS)\n",
    "\n",
    "# Combine into dict\n",
    "patches_by_label = {\n",
    "    \"light_sub_20\": light_poly_patches,\n",
    "    \"heavy_sub_10\": heavy_poly_patches,\n",
    "    \"light_sub_20_edie\": light_edie_patches,\n",
    "    \"heavy_sub_10_edie\": heavy_edie_patches\n",
    "}\n",
    "\n",
    "\n",
    "# 4. Plot\n",
    "interactive_plot_edies_polys_from_bounds(bound, patches_by_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68bb737",
   "metadata": {},
   "source": [
    "Area comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf64c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = compare_polygon_sets(\n",
    "    edie_light,\n",
    "    edie_heavy,\n",
    "    light_polys_miles,\n",
    "    heavy_polys_miles,\n",
    "    dx=DX_FEET,\n",
    "    dt=DT_SECONDS\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "congestion_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
